{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 108800 images belonging to 3 classes.\n",
      "Found 27200 images belonging to 3 classes.\n",
      "Epoch 1/10\n",
      "5440/5440 [==============================] - 2529s 465ms/step - loss: -1970542084096.0000 - accuracy: 0.5380 - val_loss: -19969744044032.0000 - val_accuracy: 0.5007\n",
      "Epoch 2/10\n",
      "5440/5440 [==============================] - 1941s 357ms/step - loss: -54745406373888.0000 - accuracy: 0.5415 - val_loss: -281598725455872.0000 - val_accuracy: 0.5387\n",
      "Epoch 3/10\n",
      "5440/5440 [==============================] - 1976s 363ms/step - loss: -347811719675904.0000 - accuracy: 0.5406 - val_loss: -1403712752844800.0000 - val_accuracy: 0.5252\n",
      "Epoch 4/10\n",
      "5440/5440 [==============================] - 1933s 355ms/step - loss: -1284476944515072.0000 - accuracy: 0.5395 - val_loss: -4466220795428864.0000 - val_accuracy: 0.5539\n",
      "Epoch 5/10\n",
      "5440/5440 [==============================] - 1939s 356ms/step - loss: -3477340814311424.0000 - accuracy: 0.5408 - val_loss: -10996425169043456.0000 - val_accuracy: 0.5377\n",
      "Epoch 6/10\n",
      "5440/5440 [==============================] - 1936s 356ms/step - loss: -7916432717250560.0000 - accuracy: 0.5409 - val_loss: -23509892916576256.0000 - val_accuracy: 0.5541\n",
      "Epoch 7/10\n",
      "5440/5440 [==============================] - 2163s 398ms/step - loss: -15810029093388288.0000 - accuracy: 0.5396 - val_loss: -45218592513327104.0000 - val_accuracy: 0.5621\n",
      "Epoch 8/10\n",
      "5440/5440 [==============================] - 1924s 354ms/step - loss: -28957474816000000.0000 - accuracy: 0.5417 - val_loss: -81438206339317760.0000 - val_accuracy: 0.5615\n",
      "Epoch 9/10\n",
      "5440/5440 [==============================] - 1920s 353ms/step - loss: -49512821074952192.0000 - accuracy: 0.5397 - val_loss: -137082445416628224.0000 - val_accuracy: 0.5450\n",
      "Epoch 10/10\n",
      "5440/5440 [==============================] - 1912s 351ms/step - loss: -79921893905268736.0000 - accuracy: 0.5402 - val_loss: -216933815958896640.0000 - val_accuracy: 0.5420\n",
      "Found 136000 images belonging to 3 classes.\n",
      "6800/6800 [==============================] - 1027s 151ms/step - loss: -122695567695413248.0000 - accuracy: 0.5346\n",
      "Test Loss: -1.2269556769541325e+17\n",
      "Test Accuracy: 0.5345661640167236\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# CNN 모델 구성\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 데이터셋 로드 및 전처리\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "data_dir = 'dataset'\n",
    "train_data = train_datagen.flow_from_directory(data_dir, target_size=(150, 150), batch_size=20, class_mode='binary', subset='training')\n",
    "valid_data = train_datagen.flow_from_directory(data_dir, target_size=(150, 150), batch_size=20, class_mode='binary', subset='validation')\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(train_data, validation_data=valid_data, epochs=10)\n",
    "\n",
    "# 모델 평가\n",
    "test_data = train_datagen.flow_from_directory(data_dir, target_size=(150, 150), batch_size=20, class_mode='binary', shuffle=False)\n",
    "loss, accuracy = model.evaluate(test_data)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CS3-36\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('ASAD_ver3.h5')  # h5 확장자로 모델 저장"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
